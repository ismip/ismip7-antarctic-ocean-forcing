{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a14810c7-2ed9-4102-8f01-5d633f6c68b6",
   "metadata": {},
   "source": [
    "Script to process ocean modelling data for ismip7\n",
    "\n",
    "created by ronja.reese@northumbria.ac.uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "219c4455-e5ed-4b48-8203-035a50edabf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import subprocess\n",
    "import os, sys, shutil\n",
    "import gsw\n",
    "from pathlib import Path\n",
    "from jinja2 import Environment, FileSystemLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09cfc188-47d3-45f0-92a0-9c7c1033fccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [ 'timmermann'] # , 'mathiot','naughten_ase_01'] \n",
    "modes = ['cold', 'warm']\n",
    "version = 'v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f23fa755-74cd-42e0-853e-99b51a8849fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = '/media/NAS2/ISMIP7/Ocean_Modelling_Data/'\n",
    "data_dir = '/media/NAS2/ISMIP7/'\n",
    "output_dir = '/media/NAS2/ISMIP7/share_with_modellers/meltmip/Ocean_Modelling_Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ced1031b-1d48-46f1-b54f-445c7cf26eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "\n",
    "def get_data_path(model):\n",
    "\tif model=='mathiot':\n",
    "\t\treturn working_dir+\"Pierre_Mathiot\"\n",
    "\tif model=='timmermann':\n",
    "\t\treturn working_dir+\"Ralph_Timmermann/TimmermannUndGoeller2017_V2\"\n",
    "\tif model=='naughten_ase_01':\n",
    "\t\treturn working_dir+\"Kaitlin_Naughten/MITgcm_ASE/RCP85_ens01\"\n",
    "\n",
    "def get_file_name(model,mode):\n",
    "\tif model=='mathiot' and mode=='cold':\t\n",
    "\t\treturn \"MATHIOT_REF_TandS_1989-2018_Ant_ISMIP6grid_withtimeaxis_compressed.nc\"\n",
    "\tif model=='mathiot' and mode=='warm':\t\n",
    "\t\treturn \"MATHIOT_WARM_TandS_2048-2098_Ant_ISMIP6grid_withtimeaxis_compressed.nc\"\n",
    "\tif model=='timmermann' and mode=='warm':\n",
    "\t\treturn \"RANGO.A1B.2000-2199.TS.aym.ismip.91levels.nc\"\n",
    "\tif model=='timmermann' and mode=='cold':\n",
    "\t\treturn \"RANGO.20C.1950-1999.TS.aym.ismip.91levels.nc\"\n",
    "\tif model=='naughten_ase_01':\n",
    "\t\treturn \"MITgcm_ASE_RCP85_ens01.nc\" # FIXME here: We need to collate Kailtin's datasets into one \n",
    "\n",
    "def combine_dataset(model, input_files):\n",
    "\tds = xr.open_mfdataset(input_files,combine = 'by_coords', concat_dim=\"time\")\n",
    "\tds.to_netcdf(get_file_name(model, 'cold'))\n",
    "\t\n",
    "def model_specific_pre_processing(model, input_file, output_file):\n",
    "\tprint('Model specific adjustments')\n",
    "\t\n",
    "\tif model=='mathiot':\n",
    "\t\told_name = [\"votemper\", \"vosaline\"]\n",
    "\t\tnew_name = [\"theta_ocean\", \"salinity_ocean\"]\n",
    "\t\n",
    "\tif model=='timmermann':\n",
    "\t\told_name = [\"anzxismip\", \"anzyismip\", \"anzzismip\", \"anzyears\", \"t\", \"temp\", \"salt\"]\n",
    "\t\tnew_name = [\"x\", \"y\", \"z\", \"time\", \"time\", \"theta_ocean\", \"salinity_ocean\"]\n",
    "\n",
    "\tds_renamed = xr.open_dataset(input_file)\n",
    "\tfor i, old_n in enumerate(old_name):\n",
    "\t\tds_renamed = ds_renamed.rename({ old_n: new_name[i]})\n",
    "\tds_renamed.to_netcdf(output_file)\n",
    "\n",
    "\n",
    "\n",
    "def further_processing_mathiot(output_file):\n",
    "\t# Add depth dimension\n",
    "\t\n",
    "\tdepth_file = os.path.join(dpath,\"mask_dim_info_NEMO_ISMIP6_grid.nc\")\n",
    "\t\n",
    "\tsubprocess.call(\"ncks -A -v depth %s %s\" %(depth_file, output_file),shell=True)\n",
    "\t# Note, this requires module load nco\n",
    "\tsubprocess.call(\"ncap2 -s 'depth=-depth' -O %s %s\" %(output_file, output_file),shell=True)\n",
    "\t\t\n",
    "\tds_coords = xr.open_dataset(working_dir+\"/Pierre_Mathiot/mask_dim_info_NEMO_ISMIP6_grid.nc\")\n",
    "\n",
    "\tds = xr.open_dataset(output_file)\n",
    "\tds['deptht'] = -1*ds_coords['depth']\n",
    "\t\t\n",
    "\ttarget_grid = xr.open_dataset(data_dir+\"/ismip_grid/ismip_8km_60m_grid.nc\")\n",
    "\n",
    "\tinterpolated = ds.interp(deptht=target_grid[\"z_extrap\"], method='linear') \n",
    "\tds.close()\n",
    "\t\t\n",
    "\tinterpolated = interpolated.drop_vars(['lat', 'lon', 'deptht'], errors='ignore')\n",
    "\t\n",
    "\tinterpolated = interpolated.fillna(-9999)\n",
    "\tencoding = {var: {'_FillValue': -9999} for var in interpolated.data_vars}\n",
    "\t\n",
    "\t\n",
    "\tinterpolated.to_netcdf(output_file , encoding=encoding, unlimited_dims='time') # FIXME?\n",
    "\tinterpolated.close()\n",
    "\treturn 0\n",
    "\n",
    "\n",
    "def further_processing_timmermann(output_file):\n",
    "    # Rename z to z_extrap\n",
    "    #subprocess.call(\"ncrename -d z,z_extrap -v z,z_extrap  %s\" %(output_file),shell=True)\n",
    "    #return 0\n",
    "    \n",
    "    # Add z_extrap variable\n",
    "    #grid_file = os.path.join(data_dir,\"ismip_grid\", \"ismip_8km_60m_grid.nc\")\n",
    "    #subprocess.call(\"ncks -A -v z_extrap,x,y %s %s\" %(grid_file, output_file),shell=True)\n",
    "\n",
    "    # interpolate\n",
    "    ds = xr.open_dataset(output_file)\n",
    "        \n",
    "    target_grid = xr.open_dataset(data_dir+\"/ismip_grid/ismip_8km_60m_grid.nc\")\n",
    "    \n",
    "    interpolated = ds.interp(z=target_grid[\"z_extrap\"], method='linear') \n",
    "    ds.close()\n",
    "    #interpolated = interpolated.drop_vars(['lat', 'lon', 'deptht'], errors='ignore')\n",
    "    \n",
    "    interpolated = interpolated.fillna(-9999)\n",
    "    encoding = {var: {'_FillValue': -9999} for var in interpolated.data_vars}\n",
    "    \n",
    "    \n",
    "    interpolated.to_netcdf(output_file , encoding=encoding, unlimited_dims='time') # FIXME?\n",
    "    interpolated.close()\n",
    "    return 0\n",
    "    \n",
    "\n",
    "def calculate_time_mean(input_file,output_file):\n",
    "    print('Calculate temporal mean')\n",
    "    \n",
    "    ds = xr.load_dataset(input_file)\n",
    "    thetamean = ds['theta_ocean'].isel(time=slice(-21,-1)).mean('time',keepdims=True,keep_attrs=True)\n",
    "    salmean = ds['salinity_ocean'].isel(time=slice(-21,-1)).mean('time',keepdims=True,keep_attrs=True)\n",
    "    timemean = ds['time'].isel(time=slice(-21,-1)).mean('time',keepdims=True,keep_attrs=True)\n",
    "    \n",
    "    ds_new = xr.Dataset({ 'theta_ocean' :  thetamean, 'salinity_ocean': salmean, 'time':timemean})\n",
    "    ds_new.attrs = ds.attrs.copy()\n",
    "    \n",
    "    ds_new['theta_ocean'].attrs = ds['theta_ocean'].attrs.copy()\n",
    "    ds_new['salinity_ocean'].attrs = ds['salinity_ocean'].attrs.copy()\n",
    "    ds_new['time'].attrs = ds['time'].attrs.copy()\n",
    "    # Copy encoding (important for _FillValue, dtype, etc.)\n",
    "    ds_new['theta_ocean'].encoding = ds['theta_ocean'].encoding.copy()\n",
    "    ds_new['salinity_ocean'].encoding = ds['salinity_ocean'].encoding.copy()\n",
    "    ds_new['time'].encoding = ds['time'].encoding.copy()\n",
    "    ds_new = ds_new.fillna(-9999)\n",
    "    encoding = {var: {'_FillValue': -9999} for var in ds_new.data_vars}\n",
    "    \n",
    "    ds_new[\"time\"].attrs[\"calendar\"] = 'proleptic_gregorian'\n",
    "    ds_new.attrs['history'] = 'test'\n",
    "    # Then copy to mounted drive\n",
    "    tmp_file = output_file.split('/')[-1]\n",
    "    ds_new.to_netcdf(tmp_file, unlimited_dims='time', encoding=encoding)\n",
    "    shutil.copy(tmp_file, output_file)\n",
    "    os.remove(tmp_file)  \n",
    "    return 0\n",
    "\t\n",
    "\t\n",
    "def remove_ice_shelf_data(input_file,output_file):\n",
    "\n",
    "\ttopography = xr.open_dataset(data_dir+\"Topography/bedmap3_ismip_8km.nc\")\n",
    "\t\n",
    "\tds = xr.open_dataset(input_file)\n",
    "\tencoding = {} # make sure to keep fill values\n",
    "\tfor var in ds.data_vars:\n",
    "\t    if '_FillValue' in ds[var].encoding:\n",
    "        \tencoding[var] = {'_FillValue': ds[var].encoding['_FillValue']}\n",
    "\tds['theta_ocean'] = ds['theta_ocean'].where(np.logical_and(topography['floating_frac']==0,topography['grounded_frac']==0), np.nan)\n",
    "\tds['salinity_ocean'] = ds['salinity_ocean'].where(np.logical_and(topography['floating_frac']==0,topography['grounded_frac']==0), np.nan)\n",
    "\tds.to_netcdf(output_file, encoding=encoding)\n",
    "\n",
    "\t\n",
    "def regrid_20m_to_60m_vertical(input_file,output_file):\n",
    "\t\n",
    "    ds = xr.open_dataset(input_file)\t\n",
    "    target_grid = xr.open_dataset(data_dir+\"/ismip_grid/ismip_8km_60m_grid.nc\")\n",
    "    \n",
    "    interpolated = ds.interp(z_extrap=target_grid[\"z\"], method='linear') \n",
    "    ds.close()\n",
    "    interpolated = interpolated.drop_vars(['lat', 'lon', 'z_extrap'], errors='ignore')\n",
    "    interpolated.to_netcdf(output_file)\n",
    "\n",
    "\n",
    "def calculate_thermal_forcing(dataset):\n",
    "\t# note that Xylars routine is for SA and CT\n",
    "    \n",
    "\tdsT = xr.open_dataset(dataset+'_T.nc') # potential temp\n",
    "\tdsS = xr.open_dataset(dataset+'_S.nc') # practical salinity\n",
    "\n",
    "\tpressure = 1028*9.81*dsT['z']*-1\n",
    "\t\n",
    "\t# Linearisation of freezing point for potential temp, practical salinity from Reese et al., 2018\n",
    "\ta = -0.0572 # deg per PSU\n",
    "\tb = 0.0788 # degC\n",
    "\tc = 7.77e-8 # degC per Pa\n",
    "\n",
    "\tpt_freeze = a*dsS['salinity_ocean'] +b - c*pressure\n",
    "\ttf = dsT['theta_ocean'] - pt_freeze\n",
    "\tds_tf = xr.Dataset({'thermal_forcing': np.squeeze(tf) })\n",
    "\tds_tf.to_netcdf(dataset+'_TF.nc')\n",
    "\n",
    "\n",
    "\n",
    "def drop_time_dimension(infile, outfile):\n",
    "\tds = xr.open_dataset(infile)\n",
    "\tds = ds.squeeze().drop_vars('time')\n",
    "\t\n",
    "\tif \"_S\" in infile:\n",
    "\t\tds_new = xr.Dataset({'salinity_ocean': ds.salinity_ocean})\n",
    "\telif \"_T\" in infile:\n",
    "\t\tds_new = xr.Dataset({'theta_ocean': ds.theta_ocean})\n",
    "\telse:\n",
    "   \t\tprint('Potentially wrong file name' )\n",
    "\tds.close()\n",
    "\tds_new.to_netcdf(outfile)\n",
    "\t\n",
    "    \n",
    "\n",
    "def get_final_name(model, mode, version):\n",
    "\tif model == 'mathiot':\n",
    "\t\treturn 'Mathiot23_'+mode+'_'+version\n",
    "\telif model == 'timmermann':\n",
    "\t\treturn 'TimmermannUndGoeller2017_'+mode+'_'+version\n",
    "\telse:\n",
    "\t\tprint('something went wrong')\n",
    "\n",
    "\n",
    "def create_namelist_files(file_in, model, mode, var):\n",
    "\n",
    "    env = Environment(loader=FileSystemLoader('./'),  trim_blocks=True, lstrip_blocks=True,  keep_trailing_newline=True)\n",
    "    template = env.get_template('namelisttemplate.nml')\n",
    "\n",
    "    if var =='S':\n",
    "        variable = 'salinity_ocean'\n",
    "    elif var=='T':\n",
    "        variable = 'theta_ocean'\n",
    "    else:\n",
    "        print('Wrong variable')\n",
    "\n",
    "    if model == 'timmermann':\n",
    "        z = 'z_extrap'\n",
    "    elif model == 'mathiot':\n",
    "        z = 'z_extrap'\n",
    "    else:\n",
    "        print('Model not defined yet')\n",
    "    file_out = os.path.join(output_dir, get_final_name(model, mode,version)+'_'+var+'.nc' )\n",
    "    file_tmp = 'tmp_'+model+mode+var+'.nc'\n",
    "    \n",
    "    namelist_name = 'namelist_'+model+'_'+mode+'_'+var+'.nml'\n",
    "    \n",
    "    data_dict = {\n",
    "        'file_in':file_in,\n",
    "        'file_out':file_out,\n",
    "        'file_out_horizontal':file_tmp,\n",
    "        'file_basin': '/media/NAS2/ISMIP7/imbie2_basins_for_ISMIP7/basinNumbers_8km.nc' ,\n",
    "        'file_topo': '/media/NAS2/ISMIP7/Topography/bedmap3_ismip_8km.nc',\n",
    "        'variable':variable,\n",
    "        'z_name':z,\n",
    "    }\n",
    "        \n",
    "    output = template.render(data_dict).replace('\\r\\n', '\\n')\n",
    "    with open(namelist_name, 'w', newline='\\n') as f:\n",
    "        f.write(output)\n",
    "\n",
    "\n",
    "def clean_directory_before_extrapolation():\n",
    "    cmd = 'rm -rf job* namelist_* output_logs tmp_*.nc'\n",
    "    subprocess.check_call(cmd,shell=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76567dc5-ab7d-46b2-b833-28d584d13fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_directory_before_extrapolation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "343bda2d-95cc-4891-9ec3-c83ecb329dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timmermann cold\n",
      "Model specific adjustments\n",
      "Calculate temporal mean\n",
      "timmermann warm\n",
      "Model specific adjustments\n",
      "Calculate temporal mean\n"
     ]
    }
   ],
   "source": [
    "# MAIN - preprocess ocean data \n",
    "\n",
    "\n",
    "for model in models:\n",
    "    for mode in modes:\n",
    "        print(model, mode)\n",
    "        \n",
    "        dpath=get_data_path(model)\n",
    "        mfile=get_file_name(model,mode)\n",
    "        \n",
    "        ## model-data specific pre-processing, do not skip\n",
    "        if \"naughten_ase\" in model: # FIXME HERE to try Naughten data processing\n",
    "            input_files =   f\"{Path(os.path.join(dpath,mfile)).stem}_*.nc\"\n",
    "            combine_dataset(model, input_files)\n",
    "        orig_file = os.path.join(dpath,mfile )\n",
    "        output_file = os.path.join(dpath, f\"{Path(orig_file).stem}_renamed.nc\")\n",
    "        model_specific_pre_processing(model,orig_file ,output_file)\n",
    "        \n",
    "        # temporal averaging\n",
    "        if model=='mathiot' and mode=='cold':\n",
    "            tap = ['1998', '2018']\n",
    "        if model=='mathiot' and mode=='warm':\n",
    "            tap = ['2078', '2098']\n",
    "        if model=='timmermann' and mode=='cold':\n",
    "            tap=['1979', '1999']\t\t\n",
    "        if model=='timmermann' and mode=='warm':\n",
    "            tap=['2179', '2199']\t\t\n",
    "        input_file = os.path.join(dpath,f\"{Path(orig_file).stem}_renamed.nc\")\n",
    "        timemean_file=os.path.join(dpath,f\"{Path(input_file).stem}\"+\"_\"+tap[0]+\"_\"+tap[1]+\".nc\")\n",
    "        calculate_time_mean(input_file,timemean_file)\n",
    "        \n",
    "        # further processing mathiot (vertical interpolation onto extrapolation grid)\n",
    "        if model=='mathiot':\n",
    "            further_processing_mathiot(timemean_file)\n",
    "        if model=='timmermann':\n",
    "            further_processing_timmermann(timemean_file)\n",
    "            \n",
    "        # remove data underneath ice shelves for consistency with CMIP forcing\n",
    "        output_file=os.path.join(dpath, f\"{Path(timemean_file).stem}_noshelf.nc\")\n",
    "        remove_ice_shelf_data(os.path.join(dpath,timemean_file), output_file)\n",
    "    \n",
    "        \n",
    "        # Create namelist file file_in, model, mode, var\n",
    "        create_namelist_files(os.path.join(dpath, output_file), model, mode, 'T')\n",
    "        create_namelist_files(os.path.join(dpath, output_file), model, mode, 'S')\n",
    "        \n",
    "        # add the file to the joblist\n",
    "        with open('joblist_horizontal.txt', 'a') as fh:\n",
    "            fh.write(\"i7aof_extrap_horizontal namelist_\"+model+\"_\"+mode+\"_T.nml\\n\")\n",
    "            fh.write(\"i7aof_extrap_horizontal namelist_\"+model+\"_\"+mode+\"_S.nml\\n\")\n",
    "        \n",
    "        with open('joblist_vertical.txt', 'a') as fv:\n",
    "            fv.write(\"i7aof_extrap_vertical namelist_\"+model+\"_\"+mode+\"_T.nml\\n\")\n",
    "            fv.write(\"i7aof_extrap_vertical namelist_\"+model+\"_\"+mode+\"_S.nml\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11125775-5ed2-4712-99eb-1488be73ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run extrapolation\n",
    "\n",
    "# extrapolation horizontal and vertical, make sure to adjust namelist files to correct folders\n",
    "# !!!! Note that this requires to install and activate the ismip7_dev environment \n",
    "\n",
    "cmd = 'parallel  --joblog joblogH.txt --bar --results output_logs --tag -j 8 < joblist_horizontal.txt'\n",
    "subprocess.check_call(cmd,shell=True)\n",
    "\n",
    "cmd = 'parallel  --joblog joblogV.txt --bar --results output_logs --tag -j 8 < joblist_vertical.txt'\n",
    "subprocess.check_call(cmd,shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3861277f-db35-4310-a5f5-93c20a775df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timmermann cold\n",
      "TimmermannUndGoeller2017_cold_v2\n",
      "Regrid to 60m vertical\n",
      "Calculate thermal forcing\n",
      "timmermann warm\n",
      "TimmermannUndGoeller2017_warm_v2\n",
      "Regrid to 60m vertical\n",
      "Calculate thermal forcing\n"
     ]
    }
   ],
   "source": [
    "# Postprocess ocean modelling data\n",
    "\n",
    "for model in models:\n",
    "\tfor mode in modes:\n",
    "\t\tprint(model, mode)\t\t\n",
    "\t\t# calculate thermal forcing\n",
    "\t\t\n",
    "\t\tfinalname= get_final_name(model, mode,version)\n",
    "\t\tprint(finalname)\n",
    "\t\t\n",
    "\t\tprint('Regrid to 60m vertical')\n",
    "\t\tinput_file = os.path.join(output_dir, finalname+'_S.nc')\n",
    "\t\toutput_file = os.path.join(output_dir, finalname+'_S2.nc')\n",
    "\t\tregrid_20m_to_60m_vertical(input_file,output_file)\n",
    "        \n",
    "\t\tinput_file = os.path.join(output_dir, finalname+'_T.nc')\n",
    "\t\toutput_file = os.path.join(output_dir, finalname+'_T2.nc')\n",
    "\t\tregrid_20m_to_60m_vertical(input_file,output_file)\n",
    "\t\t\n",
    "\t\tprint('Calculate thermal forcing')\n",
    "\t\t\n",
    "\t\tdrop_time_dimension(os.path.join(output_dir, finalname+'_S2.nc'), os.path.join(output_dir, finalname+'_S.nc') )\n",
    "\t\tdrop_time_dimension(os.path.join(output_dir, finalname+'_T2.nc'), os.path.join(output_dir, finalname+'_T.nc') )\n",
    "\t\tcalculate_thermal_forcing(os.path.join(output_dir, finalname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31f86b63-c37d-4a91-b743-6e93bd2b2b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## clean up\n",
    "cmd = 'rm -rf '+output_dir+'/*2.nc'\n",
    "subprocess.check_call(cmd,shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd174045-d7d3-4173-9ac6-7d88ebd7891a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
